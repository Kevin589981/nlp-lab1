{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 处理数据\n",
    "\n",
    " 右侧点击Add Input，找到我们的比赛，然后添加\n",
    "\n",
    " 从Kaggle输入的train.csv读取数据，随机划分为训练集(95%)和验证集(5%)\n",
    "\n",
    " 保存到/kaggle/working/data/samsum目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rouge-score transformers accelerate sentencepiece -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer\n",
    "import csv\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"准备SAMSum数据集划分\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 读取原始CSV文件\n",
    "input_csv = '/kaggle/input/nanogpt-fudannlp-cs-30040/train.csv'\n",
    "print(f\"\\n读取数据: {input_csv}\")\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# 随机打乱数据\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df = df[:200]  # 测试200条数据\n",
    "total_samples = len(df)\n",
    "print(f\"总样本数: {total_samples}\")\n",
    "\n",
    "# 计算划分点（5%作为验证集）\n",
    "val_size = int(total_samples * 0.05)\n",
    "train_size = total_samples - val_size\n",
    "\n",
    "print(f\"训练集样本数: {train_size} ({train_size/total_samples*100:.1f}%)\")\n",
    "print(f\"验证集样本数: {val_size} ({val_size/total_samples*100:.1f}%)\")\n",
    "\n",
    "# 划分数据\n",
    "train_df = df.iloc[:train_size]\n",
    "val_df = df.iloc[train_size:]\n",
    "\n",
    "# 创建输出目录\n",
    "output_dir = '/kaggle/working/data/samsum'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 保存训练集\n",
    "train_csv_path = os.path.join(output_dir, 'train.csv')\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "print(f\"\\n训练集已保存: {train_csv_path}\")\n",
    "\n",
    "# 保存验证集\n",
    "val_csv_path = os.path.join(output_dir, 'validation.csv')\n",
    "val_df.to_csv(val_csv_path, index=False)\n",
    "print(f\"验证集已保存: {val_csv_path}\")\n",
    "\n",
    "print(\"\\n数据集划分完成！\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 配置类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    配置类：包含所有可调参数\n",
    "    \"\"\"\n",
    "    # 数据集配置\n",
    "    dataset_path = '/kaggle/working/data/samsum'\n",
    "    dataset = 'samsum'\n",
    "    \n",
    "    # T5特定配置\n",
    "    model_name = 'google/flan-t5-base'  # 使用flan-t5-base\n",
    "    max_input_length = 512   # 输入最大长度\n",
    "    max_target_length = 128  # 目标最大长度\n",
    "    \n",
    "    # 训练配置\n",
    "    init_from = 'scratch'     # 'scratch' 或 'resume'\n",
    "    batch_size = 2            # 每个GPU的批次大小\n",
    "    gradient_accumulation_steps = 4  # 梯度累积步数\n",
    "    max_iters = 50            # 总训练迭代次数\n",
    "    \n",
    "    # 优化器配置（修改：降低学习率）\n",
    "    learning_rate = 5e-5      # 降低学习率\n",
    "    weight_decay = 0.01       # 减小权重衰减\n",
    "    grad_clip = 0.5           # 更严格的梯度裁剪\n",
    "    warmup_steps = 50         # 减少预热步数\n",
    "    \n",
    "    # I/O配置\n",
    "    out_dir = 'out-t5-summarization'  # checkpoint保存目录\n",
    "    eval_interval = 10        # 每多少步评估一次\n",
    "    log_interval = 5          # 每多少步打印日志\n",
    "    eval_iters = 10           # 评估时的迭代次数\n",
    "    eval_only = False         # 是否只评估不训练\n",
    "    always_save_checkpoint = True  # 是否每次评估都保存checkpoint\n",
    "    resume = False            # 是否从checkpoint恢复训练\n",
    "    \n",
    "    # ROUGE评估配置\n",
    "    eval_rouge_during_training = True\n",
    "    rouge_eval_samples = 5    # 训练时ROUGE评估的样本数\n",
    "    \n",
    "    # 系统配置\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dtype = 'float16'         # 只使用float16\n",
    "    n_gpu = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
    "    \n",
    "    # 测试/生成配置\n",
    "    num_test_samples = 10\n",
    "    temperature = 0.8\n",
    "    top_k = 50\n",
    "    top_p = 0.9\n",
    "    num_beams = 2             # beam search大小\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    T5摘要任务的Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, tokenizer, max_input_length=512, max_target_length=128):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "        # T5的任务前缀\n",
    "        self.task_prefix = \"summarize: \"\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        dialogue = row['dialogue']\n",
    "        summary = row['summary'] if 'summary' in row else \"\"\n",
    "        \n",
    "        # 添加任务前缀\n",
    "        input_text = self.task_prefix + dialogue\n",
    "        \n",
    "        # Tokenize输入\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize目标（如果存在）\n",
    "        if summary:\n",
    "            target_encoding = self.tokenizer(\n",
    "                summary,\n",
    "                max_length=self.max_target_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            labels = target_encoding.input_ids.squeeze()\n",
    "            # 将padding token设为-100（用于忽略loss）\n",
    "            labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        else:\n",
    "            labels = torch.tensor([-100] * self.max_target_length)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.squeeze(),\n",
    "            'attention_mask': input_encoding.attention_mask.squeeze(),\n",
    "            'labels': labels\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(split, tokenizer):\n",
    "    \"\"\"获取DataLoader\"\"\"\n",
    "    csv_path = os.path.join(config.dataset_path, f'{split}.csv')\n",
    "    dataset = SummarizationDataset(\n",
    "        csv_path, \n",
    "        tokenizer, \n",
    "        config.max_input_length, \n",
    "        config.max_target_length\n",
    "    )\n",
    "    \n",
    "    shuffle = (split == 'train')\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, tokenizer, device):\n",
    "    \"\"\"估计训练集和验证集上的损失\"\"\"\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    \n",
    "    # 判断是否使用了DataParallel\n",
    "    is_parallel = isinstance(model, nn.DataParallel)\n",
    "    \n",
    "    for split in ['train', 'validation']:\n",
    "        dataloader = get_dataloader(split, tokenizer)\n",
    "        losses = []\n",
    "        \n",
    "        for i, batch in enumerate(dataloader):\n",
    "            if i >= config.eval_iters:\n",
    "                break\n",
    "                \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # 修复autocast语法\n",
    "            if torch.cuda.is_available():\n",
    "                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    loss = outputs.loss\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                \n",
    "            # 如果是DataParallel，loss可能是多个GPU的结果，需要取平均\n",
    "            if is_parallel and loss.dim() > 0:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            # 检查NaN\n",
    "            if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                losses.append(loss.item())\n",
    "        \n",
    "        out[split] = np.mean(losses) if losses else float('inf')\n",
    "    \n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_rouge_during_training(model, tokenizer, device, num_samples=3):\n",
    "    \"\"\"训练过程中评估ROUGE分数\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 读取验证集\n",
    "    val_csv = os.path.join(config.dataset_path, 'validation.csv')\n",
    "    val_df = pd.read_csv(val_csv)\n",
    "    \n",
    "    # 随机选择样本\n",
    "    indices = np.random.choice(len(val_df), min(num_samples, len(val_df)), replace=False)\n",
    "    \n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    for idx in indices:\n",
    "        row = val_df.iloc[idx]\n",
    "        dialogue = row['dialogue']\n",
    "        reference_summary = row['summary']\n",
    "        \n",
    "        # 构建输入\n",
    "        input_text = \"summarize: \" + dialogue\n",
    "        input_ids = tokenizer(\n",
    "            input_text,\n",
    "            max_length=config.max_input_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).input_ids.to(device)\n",
    "        \n",
    "        try:\n",
    "            # 生成摘要（使用更保守的参数）\n",
    "            generated_ids = model.generate(\n",
    "                input_ids,\n",
    "                max_length=config.max_target_length,\n",
    "                num_beams=2,\n",
    "                temperature=1.0,\n",
    "                do_sample=False,  # 关闭采样，使用贪婪解码\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            generated_summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            # 计算ROUGE分数\n",
    "            scores = scorer.score(reference_summary, generated_summary)\n",
    "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "        except Exception as e:\n",
    "            print(f\"  生成时出错: {e}\")\n",
    "            continue\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    if rouge1_scores:\n",
    "        return {\n",
    "            'rouge1': np.mean(rouge1_scores),\n",
    "            'rouge2': np.mean(rouge2_scores),\n",
    "            'rougeL': np.mean(rougeL_scores)\n",
    "        }\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"训练主函数\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"开始训练 Flan-T5 摘要模型...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 设置随机种子\n",
    "    torch.manual_seed(1337)\n",
    "    np.random.seed(1337)\n",
    "    \n",
    "    # 创建输出目录\n",
    "    os.makedirs(config.out_dir, exist_ok=True)\n",
    "    \n",
    "    # 初始化tokenizer和模型\n",
    "    print(f\"\\n加载模型: {config.model_name}\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(config.model_name)\n",
    "    \n",
    "    # 初始化或恢复模型\n",
    "    checkpoint = None\n",
    "    if config.resume and not config.eval_only:\n",
    "        checkpoint_path = os.path.join(config.out_dir, 'checkpoint.pt')\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"从checkpoint恢复: {checkpoint_path}\")\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            model = T5ForConditionalGeneration.from_pretrained(config.model_name)\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                if k.startswith('module.'):\n",
    "                    new_state_dict[k[7:]] = v\n",
    "                else:\n",
    "                    new_state_dict[k] = v\n",
    "            model.load_state_dict(new_state_dict)\n",
    "            start_iter = checkpoint['iter_num']\n",
    "            best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        else:\n",
    "            print(\"未找到checkpoint，从头开始训练\")\n",
    "            model = T5ForConditionalGeneration.from_pretrained(config.model_name)\n",
    "            start_iter = 0\n",
    "            best_val_loss = float('inf')\n",
    "    else:\n",
    "        model = T5ForConditionalGeneration.from_pretrained(config.model_name)\n",
    "        start_iter = 0\n",
    "        best_val_loss = float('inf')\n",
    "    \n",
    "    # 设置设备\n",
    "    if config.n_gpu > 1:\n",
    "        print(f\"使用 {config.n_gpu} 个GPU进行训练\")\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        model = model.to(device)\n",
    "        model = nn.DataParallel(model)\n",
    "    else:\n",
    "        device = torch.device(config.device)\n",
    "        model = model.to(device)\n",
    "    \n",
    "    # 打印模型参数数量\n",
    "    model_for_params = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    total_params = sum(p.numel() for p in model_for_params.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model_for_params.parameters() if p.requires_grad)\n",
    "    print(f\"总参数数: {total_params/1e6:.2f}M\")\n",
    "    print(f\"可训练参数数: {trainable_params/1e6:.2f}M\")\n",
    "    \n",
    "    # 如果只是评估，直接返回\n",
    "    if config.eval_only:\n",
    "        print(\"\\neval_only=True，只进行评估\")\n",
    "        losses = estimate_loss(model, tokenizer, device)\n",
    "        print(f\"Validation loss: {losses['validation']:.4f}\")\n",
    "        return model, tokenizer\n",
    "    \n",
    "    # 初始化优化器\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    # 学习率调度器\n",
    "    train_dataloader = get_dataloader('train', tokenizer)\n",
    "    total_steps = config.max_iters\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=config.warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # 混合精度训练\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 如果恢复训练，加载优化器和调度器状态\n",
    "    if config.resume and checkpoint and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'scheduler_state_dict' in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        if 'scaler_state_dict' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    \n",
    "    # 训练循环\n",
    "    print(\"\\n开始训练循环...\")\n",
    "    print(f\"总迭代次数: {config.max_iters}\")\n",
    "    print(f\"批次大小: {config.batch_size}\")\n",
    "    print(f\"梯度累积步数: {config.gradient_accumulation_steps}\")\n",
    "    print(f\"有效批次大小: {config.batch_size * config.gradient_accumulation_steps * config.n_gpu}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    model.train()\n",
    "    train_iter = iter(train_dataloader)\n",
    "    iter_num = start_iter\n",
    "    accumulated_loss = 0.0\n",
    "    skip_update = False\n",
    "    \n",
    "    while iter_num < config.max_iters:\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # 梯度累积\n",
    "        for micro_step in range(config.gradient_accumulation_steps):\n",
    "            try:\n",
    "                batch = next(train_iter)\n",
    "            except StopIteration:\n",
    "                train_iter = iter(train_dataloader)\n",
    "                batch = next(train_iter)\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # 修复autocast语法\n",
    "            if torch.cuda.is_available():\n",
    "                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    loss = outputs.loss\n",
    "                    \n",
    "                    if isinstance(model, nn.DataParallel):\n",
    "                        if loss.dim() > 0:\n",
    "                            loss = loss.mean()\n",
    "                    \n",
    "                    if torch.isnan(loss) or torch.isinf(loss):\n",
    "                        print(f\"  警告: 检测到NaN/Inf loss，跳过此批次\")\n",
    "                        skip_update = True\n",
    "                        break\n",
    "                        \n",
    "                    loss = loss / config.gradient_accumulation_steps\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss / config.gradient_accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            accumulated_loss += loss.item()\n",
    "        \n",
    "        # 如果检测到NaN，跳过这次更新\n",
    "        if skip_update:\n",
    "            optimizer.zero_grad()\n",
    "            skip_update = False\n",
    "            accumulated_loss = 0.0\n",
    "            continue\n",
    "        \n",
    "        # 梯度裁剪\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "            model.module.parameters() if isinstance(model, nn.DataParallel) else model.parameters(),\n",
    "            config.grad_clip\n",
    "        )\n",
    "        \n",
    "        # 如果梯度有NaN，跳过更新\n",
    "        if torch.isnan(grad_norm) or torch.isinf(grad_norm):\n",
    "            print(f\"  警告: 检测到NaN/Inf梯度，跳过更新\")\n",
    "            optimizer.zero_grad()\n",
    "            accumulated_loss = 0.0\n",
    "            continue\n",
    "        \n",
    "        # 优化器步骤\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 日志记录\n",
    "        if iter_num % config.log_interval == 0:\n",
    "            t1 = time.time()\n",
    "            dt = t1 - t0\n",
    "            lossf = accumulated_loss * config.gradient_accumulation_steps\n",
    "            if not np.isnan(lossf):\n",
    "                print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, lr {scheduler.get_last_lr()[0]:.2e}\")\n",
    "            else:\n",
    "                print(f\"iter {iter_num}: loss NaN detected, time {dt*1000:.2f}ms\")\n",
    "        \n",
    "        # 评估\n",
    "        if iter_num % config.eval_interval == 0 and iter_num > 0:\n",
    "            losses = estimate_loss(model, tokenizer, device)\n",
    "            if not np.isnan(losses['train']) and not np.isnan(losses['validation']):\n",
    "                print(f\"\\nStep {iter_num}: train loss {losses['train']:.4f}, val loss {losses['validation']:.4f}\")\n",
    "                \n",
    "                # ROUGE评估\n",
    "                if config.eval_rouge_during_training:\n",
    "                    print(\"  评估ROUGE分数...\")\n",
    "                    eval_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "                    rouge_scores = evaluate_rouge_during_training(\n",
    "                        eval_model, tokenizer, device, \n",
    "                        num_samples=config.rouge_eval_samples\n",
    "                    )\n",
    "                    if rouge_scores:\n",
    "                        print(f\"  ROUGE-1: {rouge_scores['rouge1']:.4f}, \"\n",
    "                              f\"ROUGE-2: {rouge_scores['rouge2']:.4f}, \"\n",
    "                              f\"ROUGE-L: {rouge_scores['rougeL']:.4f}\")\n",
    "                \n",
    "                # 保存checkpoint\n",
    "                if losses['validation'] < best_val_loss or config.always_save_checkpoint:\n",
    "                    best_val_loss = losses['validation']\n",
    "                    \n",
    "                    model_to_save = model.module if isinstance(model, nn.DataParallel) else model\n",
    "                    \n",
    "                    checkpoint = {\n",
    "                        'model_state_dict': model_to_save.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict(),\n",
    "                        'scaler_state_dict': scaler.state_dict(),\n",
    "                        'iter_num': iter_num,\n",
    "                        'best_val_loss': best_val_loss,\n",
    "                        'config': vars(config)\n",
    "                    }\n",
    "                    \n",
    "                    checkpoint_path = os.path.join(config.out_dir, 'checkpoint.pt')\n",
    "                    torch.save(checkpoint, checkpoint_path)\n",
    "                    print(f\"  保存checkpoint到 {checkpoint_path}\")\n",
    "                    \n",
    "                    model_to_save.save_pretrained(os.path.join(config.out_dir, 'model'))\n",
    "                    tokenizer.save_pretrained(os.path.join(config.out_dir, 'model'))\n",
    "            else:\n",
    "                print(f\"\\nStep {iter_num}: 检测到NaN loss，跳过评估\")\n",
    "        \n",
    "        accumulated_loss = 0.0\n",
    "        iter_num += 1\n",
    "    \n",
    "    print(\"\\n训练完成！\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    \"\"\"评估模型性能\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"开始评估...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 加载模型\n",
    "    model_path = os.path.join(config.out_dir, 'model')\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"从 {model_path} 加载模型\")\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(config.out_dir, 'checkpoint.pt')\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"从checkpoint加载模型: {checkpoint_path}\")\n",
    "            tokenizer = T5Tokenizer.from_pretrained(config.model_name)\n",
    "            model = T5ForConditionalGeneration.from_pretrained(config.model_name)\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            # 处理可能的DataParallel wrapper\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                if k.startswith('module.'):\n",
    "                    new_state_dict[k[7:]] = v\n",
    "                else:\n",
    "                    new_state_dict[k] = v\n",
    "            model.load_state_dict(new_state_dict)\n",
    "        else:\n",
    "            print(\"错误: 未找到训练好的模型\")\n",
    "            return\n",
    "    \n",
    "    device = torch.device(config.device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 加载测试数据\n",
    "    val_csv = os.path.join(config.dataset_path, 'validation.csv')\n",
    "    val_df = pd.read_csv(val_csv)\n",
    "    \n",
    "    # 限制测试样本数量\n",
    "    test_samples = min(config.num_test_samples, len(val_df))\n",
    "    val_df = val_df.head(test_samples)\n",
    "    \n",
    "    print(f\"评估 {test_samples} 个样本\")\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    all_rouge1 = []\n",
    "    all_rouge2 = []\n",
    "    all_rougeL = []\n",
    "    \n",
    "    for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=\"生成摘要\"):\n",
    "        dialogue = row['dialogue']\n",
    "        reference_summary = row['summary']\n",
    "        \n",
    "        # 构建输入\n",
    "        input_text = \"summarize: \" + dialogue\n",
    "        input_ids = tokenizer(\n",
    "            input_text,\n",
    "            max_length=config.max_input_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).input_ids.to(device)\n",
    "        \n",
    "        # 生成摘要\n",
    "        with torch.no_grad():\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
    "                generated_ids = model.generate(\n",
    "                    input_ids,\n",
    "                    max_length=config.max_target_length,\n",
    "                    num_beams=config.num_beams,\n",
    "                    temperature=config.temperature,\n",
    "                    do_sample=True,\n",
    "                    top_k=config.top_k,\n",
    "                    top_p=config.top_p,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "        \n",
    "        generated_summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 计算ROUGE分数\n",
    "        scores = scorer.score(reference_summary, generated_summary)\n",
    "        all_rouge1.append(scores['rouge1'].fmeasure)\n",
    "        all_rouge2.append(scores['rouge2'].fmeasure)\n",
    "        all_rougeL.append(scores['rougeL'].fmeasure)\n",
    "        \n",
    "        if idx < 3:  # 打印前3个样本\n",
    "            print(f\"\\n样本 {idx+1}:\")\n",
    "            print(f\"对话: {dialogue[:200]}...\")\n",
    "            print(f\"参考摘要: {reference_summary}\")\n",
    "            print(f\"生成摘要: {generated_summary}\")\n",
    "            print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
    "    \n",
    "    # 打印平均分数\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"平均ROUGE分数:\")\n",
    "    print(f\"  ROUGE-1: {np.mean(all_rouge1):.4f}\")\n",
    "    print(f\"  ROUGE-2: {np.mean(all_rouge2):.4f}\")\n",
    "    print(f\"  ROUGE-L: {np.mean(all_rougeL):.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "def predict_test_set():\n",
    "    \"\"\"对测试集进行预测\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"开始对测试集进行预测...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 加载模型\n",
    "    model_path = os.path.join(config.out_dir, 'model')\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"从 {model_path} 加载模型\")\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(config.out_dir, 'checkpoint.pt')\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"从checkpoint加载模型: {checkpoint_path}\")\n",
    "            tokenizer = T5Tokenizer.from_pretrained(config.model_name)\n",
    "            model = T5ForConditionalGeneration.from_pretrained(config.model_name)\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            # 处理可能的DataParallel wrapper\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                if k.startswith('module.'):\n",
    "                    new_state_dict[k[7:]] = v\n",
    "                else:\n",
    "                    new_state_dict[k] = v\n",
    "            model.load_state_dict(new_state_dict)\n",
    "        else:\n",
    "            print(\"错误: 未找到训练好的模型\")\n",
    "            return\n",
    "    \n",
    "    device = torch.device(config.device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 读取测试数据\n",
    "    test_file = '/kaggle/input/nanogpt-fudannlp-cs-30040/test.csv'\n",
    "    if not os.path.exists(test_file):\n",
    "        print(f\"错误: 找不到测试文件 {test_file}\")\n",
    "        return\n",
    "    \n",
    "    test_df = pd.read_csv(test_file)\n",
    "    print(f\"加载了 {len(test_df)} 条测试样本\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"生成摘要\"):\n",
    "        sample_id = row['id']\n",
    "        dialogue = row['dialogue']\n",
    "        \n",
    "        # 构建输入\n",
    "        input_text = \"summarize: \" + dialogue\n",
    "        input_ids = tokenizer(\n",
    "            input_text,\n",
    "            max_length=config.max_input_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).input_ids.to(device)\n",
    "        \n",
    "        # 生成摘要\n",
    "        with torch.no_grad():\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
    "                generated_ids = model.generate(\n",
    "                    input_ids,\n",
    "                    max_length=config.max_target_length,\n",
    "                    num_beams=config.num_beams,\n",
    "                    temperature=config.temperature,\n",
    "                    do_sample=True,\n",
    "                    top_k=config.top_k,\n",
    "                    top_p=config.top_p,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "        \n",
    "        generated_summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        results.append({\n",
    "            'id': sample_id,\n",
    "            'summary': generated_summary\n",
    "        })\n",
    "    \n",
    "    # 保存结果\n",
    "    output_file = os.path.join(config.out_dir, 'submission.csv')\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n预测完成！结果保存到: {output_file}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    print(\"\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Flan-T5 摘要微调\".center(80))\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n当前配置:\")\n",
    "    print(f\"  模型: {config.model_name}\")\n",
    "    print(f\"  数据集: {config.dataset_path}\")\n",
    "    print(f\"  设备: {config.device}\")\n",
    "    print(f\"  GPU数量: {config.n_gpu}\")\n",
    "    print(f\"  批次大小: {config.batch_size}\")\n",
    "    print(f\"  最大迭代次数: {config.max_iters}\")\n",
    "    print(f\"  学习率: {config.learning_rate}\")\n",
    "    print(f\"  评估模式: {config.eval_only}\")\n",
    "    print(f\"  恢复训练: {config.resume}\")\n",
    "    \n",
    "    # 训练模型\n",
    "    model, tokenizer = train()\n",
    "    \n",
    "    # 评估模型\n",
    "    evaluate()\n",
    "    \n",
    "    # 对测试集进行预测\n",
    "    predict_test_set()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
