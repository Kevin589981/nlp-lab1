# Kaggle 2-GPU è®­ç»ƒè®¾ç½®æŒ‡å—

## å¿«é€Ÿå¼€å§‹

### 1. åœ¨Kaggle Notebookä¸­è®¾ç½®

1. åˆ›å»ºæ–°çš„Kaggle Notebook
2. åœ¨å³ä¾§è®¾ç½®ä¸­é€‰æ‹© **"GPU T4 x2"** (2ä¸ªTesla T4 GPU)
3. ä¸Šä¼  `version12.py` æ–‡ä»¶

### 2. å®‰è£…ä¾èµ–

åœ¨ç¬¬ä¸€ä¸ªcellä¸­è¿è¡Œï¼š

```python
!pip install rouge-score
```

### 3. å‡†å¤‡æ•°æ®

ç¡®ä¿ä½ çš„æ•°æ®é›†å·²ç»æ·»åŠ åˆ°Notebookè¾“å…¥ä¸­ï¼š
- è®­ç»ƒæ•°æ®: `/kaggle/input/nanogpt-fudannlp-cs-30040/train.csv`
- æµ‹è¯•æ•°æ®: `/kaggle/input/nanogpt-fudannlp-cs-30040/test.csv`

### 4. å¯åŠ¨è®­ç»ƒ

#### æ–¹æ³•A: ä½¿ç”¨torchrunï¼ˆæ¨èï¼‰

```python
!torchrun --nproc_per_node=2 --standalone version12.py
```

#### æ–¹æ³•B: ä½¿ç”¨å¯åŠ¨è„šæœ¬

é¦–å…ˆåˆ›å»º `train_ddp.py`ï¼Œç„¶åè¿è¡Œï¼š

```python
!python train_ddp.py
```

## ä»£ç ä¿®æ”¹è¯´æ˜

### å…³é”®ä¿®æ”¹ç‚¹

1. **Configç±»æ·»åŠ DDPæ”¯æŒ**
```python
class Config:
    # ...
    ddp = True  # å¯ç”¨DDP
    gradient_accumulation_steps = 8  # ä»16æ”¹ä¸º8ï¼ˆå› ä¸ºæœ‰2ä¸ªGPUï¼‰
```

2. **train()å‡½æ•°æ·»åŠ DDPåˆå§‹åŒ–**
```python
def train():
    # DDPè®¾ç½®
    ddp = config.ddp and torch.cuda.device_count() > 1
    if ddp:
        init_process_group(backend=config.backend)
        ddp_rank = int(os.environ['RANK'])
        ddp_local_rank = int(os.environ['LOCAL_RANK'])
        ddp_world_size = int(os.environ['WORLD_SIZE'])
        device = f'cuda:{ddp_local_rank}'
        torch.cuda.set_device(device)
        master_process = ddp_rank == 0
```

3. **æ¨¡å‹ç”¨DDPåŒ…è£…**
```python
if ddp:
    model = DDP(model, device_ids=[ddp_local_rank])
```

4. **åªåœ¨ä¸»è¿›ç¨‹æ‰“å°å’Œä¿å­˜**
```python
if master_process:
    print(f"Step {iter_num}: train loss {losses['train']:.4f}")
    torch.save(checkpoint, os.path.join(config.out_dir, 'ckpt.pt'))
```

## é¢„æœŸæ€§èƒ½

### è®­ç»ƒé€Ÿåº¦
- **å•GPU**: ~2000ms/iteration
- **2 GPU (DDP)**: ~1100ms/iteration
- **åŠ é€Ÿæ¯”**: ~1.8x

### æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
```
batch_size Ã— gradient_accumulation_steps Ã— num_gpus
= 16 Ã— 8 Ã— 2
= 256
```

### å†…å­˜ä½¿ç”¨
- æ¯ä¸ªGPU: ~14GB (Tesla T4æœ‰16GB)
- ä¸¤ä¸ªGPUç‹¬ç«‹åŠ è½½æ¨¡å‹å‰¯æœ¬

## éªŒè¯DDPæ˜¯å¦æ­£å¸¸å·¥ä½œ

è®­ç»ƒå¼€å§‹æ—¶åº”è¯¥çœ‹åˆ°ï¼š

```
================================================================================
å¼€å§‹è®­ç»ƒ...
================================================================================
DDPè®­ç»ƒ: 2 GPUs

ä» out-summarization åŠ è½½è¯è¡¨å¤§å°: 50257
æ¨¡å‹åˆå§‹åŒ–æ–¹å¼: gpt2
ä»OpenAI GPT-2åŠ è½½: gpt2
...

å¼€å§‹è®­ç»ƒå¾ªç¯...
æ€»è¿­ä»£æ¬¡æ•°: 500
æ‰¹æ¬¡å¤§å°: 16
æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: 8
æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: 256
--------------------------------------------------------------------------------
```

å…³é”®æŒ‡æ ‡ï¼š
- âœ… æ˜¾ç¤º "DDPè®­ç»ƒ: 2 GPUs"
- âœ… æœ‰æ•ˆæ‰¹æ¬¡å¤§å°ä¸º 256
- âœ… æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ä¸º 8ï¼ˆä¸æ˜¯16ï¼‰

## ç›‘æ§GPUä½¿ç”¨

åœ¨å¦ä¸€ä¸ªterminalæˆ–cellä¸­è¿è¡Œï¼š

```python
!watch -n 1 nvidia-smi
```

åº”è¯¥çœ‹åˆ°ä¸¤ä¸ªGPUéƒ½åœ¨ä½¿ç”¨ï¼Œåˆ©ç”¨ç‡æ¥è¿‘100%ã€‚

## å¸¸è§é—®é¢˜

### Q1: åªçœ‹åˆ°1ä¸ªGPUåœ¨å·¥ä½œ

**åŸå› **: Kaggleè®¾ç½®ä¸­æ²¡æœ‰é€‰æ‹© "GPU T4 x2"

**è§£å†³**: 
1. ç‚¹å‡»å³ä¾§ "Accelerator"
2. é€‰æ‹© "GPU T4 x2"
3. é‡å¯Notebook

### Q2: "RuntimeError: Address already in use"

**åŸå› **: ç«¯å£è¢«å ç”¨

**è§£å†³**: æŒ‡å®šä¸åŒç«¯å£
```python
!torchrun --nproc_per_node=2 --master_port=29501 --standalone version12.py
```

### Q3: NCCLé€šä¿¡é”™è¯¯

**è§£å†³**: åœ¨ä»£ç å¼€å§‹æ·»åŠ ç¯å¢ƒå˜é‡
```python
import os
os.environ['NCCL_DEBUG'] = 'INFO'
os.environ['NCCL_P2P_DISABLE'] = '1'
```

### Q4: æƒ³è¦å•GPUè®­ç»ƒ

**è§£å†³**: ä¿®æ”¹Config
```python
class Config:
    ddp = False  # ç¦ç”¨DDP
    gradient_accumulation_steps = 16  # æ¢å¤ä¸º16
```

## å®Œæ•´çš„Kaggle Notebookç¤ºä¾‹

```python
# Cell 1: å®‰è£…ä¾èµ–
!pip install rouge-score

# Cell 2: æ£€æŸ¥GPU
import torch
print(f"å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
for i in range(torch.cuda.device_count()):
    print(f"GPU {i}: {torch.cuda.get_device_name(i)}")

# Cell 3: å¯åŠ¨è®­ç»ƒ
!torchrun --nproc_per_node=2 --standalone version12.py

# Cell 4: æŸ¥çœ‹ç»“æœ
!ls -lh out-summarization/

# Cell 5: è¿è¡Œè¯„ä¼°ï¼ˆåœ¨è®­ç»ƒå®Œæˆåï¼‰
# æ³¨æ„ï¼šè¯„ä¼°åº”è¯¥åœ¨å•GPUä¸Šè¿è¡Œ
import version12
version12.config.ddp = False  # ç¦ç”¨DDPè¿›è¡Œè¯„ä¼°
version12.evaluate()

# Cell 6: ç”Ÿæˆæäº¤æ–‡ä»¶
version12.predict_test_set_fast()
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **è°ƒæ•´æ‰¹æ¬¡å¤§å°**: å¦‚æœGPUå†…å­˜å……è¶³ï¼Œå¯ä»¥å¢åŠ  `batch_size`
2. **ä½¿ç”¨æ··åˆç²¾åº¦**: å·²å¯ç”¨ `dtype='float16'`
3. **ç¼–è¯‘æ¨¡å‹**: å·²å¯ç”¨ `compile=True` (PyTorch 2.0+)
4. **KV Cache**: æ¨ç†æ—¶ä½¿ç”¨ `generate_with_kv_cache` åŠ é€Ÿ

## æˆæœ¬è€ƒè™‘

Kaggleå…è´¹æä¾›ï¼š
- æ¯å‘¨30å°æ—¶GPUæ—¶é—´
- 2ä¸ªT4 GPUåŒæ—¶ä½¿ç”¨è®¡ä¸º2å€æ—¶é—´
- è®­ç»ƒ500 iterationsçº¦éœ€1-2å°æ—¶ï¼ˆä½¿ç”¨2ä¸ªGPUï¼‰

## ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼š
1. æ£€æŸ¥ `out-summarization/ckpt.pt` æ˜¯å¦ç”Ÿæˆ
2. è¿è¡Œè¯„ä¼°æŸ¥çœ‹ROUGEåˆ†æ•°
3. ç”Ÿæˆæµ‹è¯•é›†é¢„æµ‹
4. ä¸‹è½½ `submission.csv` æäº¤

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
